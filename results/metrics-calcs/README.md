# README
This repo contains scripts and data for METIS debloated binary evaluations related to:
- GSA
- Dynamic libraries and File Size
- Differ

# Layout
- `scripts`: general python scripts for running experiments and evaluating results
- `results/gsa`: GSA experiment results
- `results/file-stats`: Dynamic library and file size results
- `results/differ`: differ experiment results
- `eval-scripts`: scripts for specific experiment runs
- `environment`: scripts and dockerfiles for configuring experiment environments
- `batches`: config files specifying each batch that was run

# Differ Results Layout
Layout of the folders in `results/differ`:
- each `roundN/` directory stores results from a round of differ campaigns and have the same structure
    - `round2` campaigns overlap with `round1` because `round2` campaigns are those that failed during `round1` for various reasons
    - `round3` contains the final data used in the paper
- `roundN/*.json`: these files contain the fail counts per binary, not adjusted for false positives
- `roundN/check-false-positives`: stores the output of scripts that checked each campaign's crash/error reports for false positives
- `roundN/raw`: store zips with raw report directories generated by the differ runs in `eval-scripts/`
    - these zips are stored with `git lfs`

# Helpful Notes
Some data is stored with git LFS. In total, these are GB of data. If you have git lfs installed and don't want to download these files,
run `export GIT_LFS_SKIP_SMUDGE=1` first.
